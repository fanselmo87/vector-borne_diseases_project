{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f6f901",
   "metadata": {},
   "source": [
    "## Carregando os dados e checando se está ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f300f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Dengue</th>\n",
       "      <th>Zika</th>\n",
       "      <th>Chik</th>\n",
       "      <th>LeishVis</th>\n",
       "      <th>LeishTeg</th>\n",
       "      <th>LeishT</th>\n",
       "      <th>Precipt</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>AvgHumid</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>Season</th>\n",
       "      <th>Season2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>2901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>138.90</td>\n",
       "      <td>25.12</td>\n",
       "      <td>25.86</td>\n",
       "      <td>24.41</td>\n",
       "      <td>64.82</td>\n",
       "      <td>1.56</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Fevereiro</td>\n",
       "      <td>10196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>52</td>\n",
       "      <td>139.67</td>\n",
       "      <td>25.79</td>\n",
       "      <td>26.49</td>\n",
       "      <td>25.10</td>\n",
       "      <td>58.32</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>Marco</td>\n",
       "      <td>29647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>150.00</td>\n",
       "      <td>23.86</td>\n",
       "      <td>24.47</td>\n",
       "      <td>23.23</td>\n",
       "      <td>70.44</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>Abril</td>\n",
       "      <td>85767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>103.92</td>\n",
       "      <td>22.12</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.59</td>\n",
       "      <td>74.90</td>\n",
       "      <td>1.49</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Maio</td>\n",
       "      <td>62901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>57.20</td>\n",
       "      <td>19.72</td>\n",
       "      <td>20.28</td>\n",
       "      <td>19.18</td>\n",
       "      <td>70.97</td>\n",
       "      <td>1.44</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano        Mes  Dengue  Zika  Chik  LeishVis  LeishTeg  LeishT  Precipt  \\\n",
       "0  2014    Janeiro    2901   NaN   NaN        15        31      46   138.90   \n",
       "1  2014  Fevereiro   10196   NaN   NaN        20        32      52   139.67   \n",
       "2  2014      Marco   29647   NaN   NaN        18        29      47   150.00   \n",
       "3  2014      Abril   85767   NaN   NaN        20        22      42   103.92   \n",
       "4  2014       Maio   62901   NaN   NaN        15        16      31    57.20   \n",
       "\n",
       "   AvgTemp  MaxTemp  MinTemp  AvgHumid  AvgWin  Season Season2  \n",
       "0    25.12    25.86    24.41     64.82    1.56  Summer     Wet  \n",
       "1    25.79    26.49    25.10     58.32    1.74  Summer     Wet  \n",
       "2    23.86    24.47    23.23     70.44    1.74  Summer     Wet  \n",
       "3    22.12    22.69    21.59     74.90    1.49    Fall     Dry  \n",
       "4    19.72    20.28    19.18     70.97    1.44    Fall     Dry  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "csv_path = Path(r\"C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\") / \"Dataset_Modelos_Computacionais_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f33c2",
   "metadata": {},
   "source": [
    "##Medidas descritivas (geral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90434b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Dengue</th>\n",
       "      <th>Zika</th>\n",
       "      <th>Chik</th>\n",
       "      <th>LeishVis</th>\n",
       "      <th>LeishTeg</th>\n",
       "      <th>LeishT</th>\n",
       "      <th>Precipt</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>AvgHumid</th>\n",
       "      <th>AvgWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>37008.848485</td>\n",
       "      <td>215.425926</td>\n",
       "      <td>927.187500</td>\n",
       "      <td>10.909091</td>\n",
       "      <td>27.848485</td>\n",
       "      <td>38.757576</td>\n",
       "      <td>119.955227</td>\n",
       "      <td>22.179091</td>\n",
       "      <td>22.785227</td>\n",
       "      <td>21.577424</td>\n",
       "      <td>68.240758</td>\n",
       "      <td>1.579091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.174324</td>\n",
       "      <td>88805.108924</td>\n",
       "      <td>414.422720</td>\n",
       "      <td>1432.025759</td>\n",
       "      <td>4.457526</td>\n",
       "      <td>8.631104</td>\n",
       "      <td>10.511441</td>\n",
       "      <td>80.096108</td>\n",
       "      <td>2.207175</td>\n",
       "      <td>2.269410</td>\n",
       "      <td>2.236895</td>\n",
       "      <td>6.332219</td>\n",
       "      <td>0.223120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>15.650000</td>\n",
       "      <td>50.140000</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1681.500000</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>265.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>50.580000</td>\n",
       "      <td>20.165000</td>\n",
       "      <td>20.742500</td>\n",
       "      <td>19.527500</td>\n",
       "      <td>64.165000</td>\n",
       "      <td>1.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>5134.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>111.070000</td>\n",
       "      <td>22.955000</td>\n",
       "      <td>23.560000</td>\n",
       "      <td>22.385000</td>\n",
       "      <td>68.915000</td>\n",
       "      <td>1.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>32834.250000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>875.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>168.655000</td>\n",
       "      <td>23.912500</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>23.322500</td>\n",
       "      <td>73.152500</td>\n",
       "      <td>1.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.000000</td>\n",
       "      <td>619390.000000</td>\n",
       "      <td>2874.000000</td>\n",
       "      <td>8154.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>370.270000</td>\n",
       "      <td>25.960000</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>25.290000</td>\n",
       "      <td>79.880000</td>\n",
       "      <td>2.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ano         Dengue         Zika         Chik    LeishVis  \\\n",
       "count   132.000000     132.000000   108.000000    96.000000  132.000000   \n",
       "mean   2019.000000   37008.848485   215.425926   927.187500   10.909091   \n",
       "std       3.174324   88805.108924   414.422720  1432.025759    4.457526   \n",
       "min    2014.000000     310.000000    28.000000    96.000000    2.000000   \n",
       "25%    2016.000000    1681.500000    68.750000   265.500000    7.000000   \n",
       "50%    2019.000000    5134.500000   109.000000   387.000000   11.000000   \n",
       "75%    2022.000000   32834.250000   178.000000   875.250000   14.000000   \n",
       "max    2024.000000  619390.000000  2874.000000  8154.000000   22.000000   \n",
       "\n",
       "         LeishTeg      LeishT     Precipt     AvgTemp     MaxTemp     MinTemp  \\\n",
       "count  132.000000  132.000000  132.000000  132.000000  132.000000  132.000000   \n",
       "mean    27.848485   38.757576  119.955227   22.179091   22.785227   21.577424   \n",
       "std      8.631104   10.511441   80.096108    2.207175    2.269410    2.236895   \n",
       "min      7.000000   12.000000    4.970000   16.850000   16.750000   15.650000   \n",
       "25%     22.000000   31.750000   50.580000   20.165000   20.742500   19.527500   \n",
       "50%     27.000000   38.000000  111.070000   22.955000   23.560000   22.385000   \n",
       "75%     33.250000   46.000000  168.655000   23.912500   24.530000   23.322500   \n",
       "max     54.000000   66.000000  370.270000   25.960000   26.660000   25.290000   \n",
       "\n",
       "         AvgHumid      AvgWin  \n",
       "count  132.000000  132.000000  \n",
       "mean    68.240758    1.579091  \n",
       "std      6.332219    0.223120  \n",
       "min     50.140000    1.140000  \n",
       "25%     64.165000    1.420000  \n",
       "50%     68.915000    1.565000  \n",
       "75%     73.152500    1.755000  \n",
       "max     79.880000    2.070000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560abec",
   "metadata": {},
   "source": [
    "## df.info descreve as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5c8c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132 entries, 0 to 131\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Ano       132 non-null    int64  \n",
      " 1   Mes       132 non-null    object \n",
      " 2   Dengue    132 non-null    int64  \n",
      " 3   Zika      108 non-null    float64\n",
      " 4   Chik      96 non-null     float64\n",
      " 5   LeishVis  132 non-null    int64  \n",
      " 6   LeishTeg  132 non-null    int64  \n",
      " 7   LeishT    132 non-null    int64  \n",
      " 8   Precipt   132 non-null    float64\n",
      " 9   AvgTemp   132 non-null    float64\n",
      " 10  MaxTemp   132 non-null    float64\n",
      " 11  MinTemp   132 non-null    float64\n",
      " 12  AvgHumid  132 non-null    float64\n",
      " 13  AvgWin    132 non-null    float64\n",
      " 14  Season    132 non-null    object \n",
      " 15  Season2   132 non-null    object \n",
      "dtypes: float64(8), int64(5), object(3)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593fcb5",
   "metadata": {},
   "source": [
    "## Pré tratamento dos dados:\n",
    "- Criar uma coluna \"Data\" para armazenar informação de mês e ano (não será uma variável preditora)\n",
    "- Retirar ano;\n",
    "- Retirar mês;\n",
    "- Deixar apenas temperatura média\n",
    "- Excluir variáveis preditoras colineares com VIF>10;\n",
    "- Excluir outliers dos números de casos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5580a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando a coluna data\n",
    "# -----------------------------------------------------------\n",
    "# 2. Criar coluna de DATA a partir de Ano + Mes\n",
    "# -----------------------------------------------------------\n",
    "mes_map = {\n",
    "    \"Janeiro\": 1,\n",
    "    \"Fevereiro\": 2,\n",
    "    \"Marco\": 3,\n",
    "    \"Março\": 3,  # caso apareça com acento\n",
    "    \"Abril\": 4,\n",
    "    \"Maio\": 5,\n",
    "    \"Junho\": 6,\n",
    "    \"Julho\": 7,\n",
    "    \"Agosto\": 8,\n",
    "    \"Setembro\": 9,\n",
    "    \"Outubro\": 10,\n",
    "    \"Novembro\": 11,\n",
    "    \"Dezembro\": 12\n",
    "}\n",
    "\n",
    "df[\"MesNum\"] = df[\"Mes\"].map(mes_map)\n",
    "\n",
    "# cria coluna Data (vou usar dia 1 de cada mês)\n",
    "df[\"Data\"] = pd.to_datetime(dict(year=df[\"Ano\"], month=df[\"MesNum\"], day=1))\n",
    "\n",
    "# definir Data como índice temporal e ordenar\n",
    "df = df.set_index(\"Data\").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a96a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dengue  Zika  Chik  LeishVis  LeishTeg  LeishT  Precipt  AvgTemp  \\\n",
      "Data                                                                           \n",
      "2014-01-01    2901   NaN   NaN        15        31      46   138.90    25.12   \n",
      "2014-02-01   10196   NaN   NaN        20        32      52   139.67    25.79   \n",
      "2014-03-01   29647   NaN   NaN        18        29      47   150.00    23.86   \n",
      "2014-04-01   85767   NaN   NaN        20        22      42   103.92    22.12   \n",
      "2014-05-01   62901   NaN   NaN        15        16      31    57.20    19.72   \n",
      "\n",
      "            AvgHumid  AvgWin  Season Season2  \n",
      "Data                                          \n",
      "2014-01-01     64.82    1.56  Summer     Wet  \n",
      "2014-02-01     58.32    1.74  Summer     Wet  \n",
      "2014-03-01     70.44    1.74  Summer     Wet  \n",
      "2014-04-01     74.90    1.49    Fall     Dry  \n",
      "2014-05-01     70.97    1.44    Fall     Dry  \n"
     ]
    }
   ],
   "source": [
    "## Removendo ano, mês, temperatura máxima e mínima\n",
    "df = df.drop(columns=[\"Ano\", \"Mes\", \"MesNum\", \"MinTemp\", \"MaxTemp\"])\n",
    "\n",
    "\n",
    "# Check the result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4590e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carregando biblioteca para cálculo do VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a478132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela de VIF (antes da exclusão):\n",
      "   variavel         VIF\n",
      "0   AvgTemp  111.903118\n",
      "1  AvgHumid   72.214836\n",
      "2    AvgWin   50.060495\n",
      "3   Precipt    4.322273\n",
      "\n",
      "Variáveis com VIF > 10 (candidatas à exclusão):\n",
      "['AvgTemp', 'AvgHumid', 'AvgWin']\n",
      "\n",
      "Colunas finais em df_sem_colinear (após remover VIF > 10):\n",
      "Index(['Dengue', 'Zika', 'Chik', 'LeishVis', 'LeishTeg', 'LeishT', 'Precipt',\n",
      "       'MaxTemp', 'MinTemp', 'Season', 'Season2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1. Carregar o dataset\n",
    "# -------------------------------------------------------------------\n",
    "csv_path = Path(r\"C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\") / \"Dataset_Modelos_Computacionais_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Remover colunas \"Ano\" e \"Mes\" (já decidido no seu projeto)\n",
    "# -------------------------------------------------------------------\n",
    "df = df.drop(columns=[\"Ano\", \"Mes\"])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Definir quais variáveis vão entrar no cálculo do VIF\n",
    "#    Aqui eu assumo que você quer modelar, por exemplo, DENGUE.\n",
    "#    Então as preditoras são as variáveis climáticas numéricas.\n",
    "# -------------------------------------------------------------------\n",
    "# Se quiser mudar o alvo depois (ex: \"Zika\"), basta trocar aqui.\n",
    "target = \"Dengue\"\n",
    "\n",
    "# Lista de preditoras que vão para o VIF (climáticas)\n",
    "preditoras_vif = [\"Precipt\", \"AvgTemp\", \"AvgHumid\", \"AvgWin\"]\n",
    "\n",
    "# Criar matriz X só com essas colunas (sem valores faltantes)\n",
    "X = df[preditoras_vif].dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Calcular o VIF para cada preditora\n",
    "# -------------------------------------------------------------------\n",
    "vif_table = pd.DataFrame()\n",
    "vif_table[\"variavel\"] = preditoras_vif\n",
    "vif_table[\"VIF\"] = [\n",
    "    variance_inflation_factor(X.values, i)\n",
    "    for i in range(X.shape[1])\n",
    "]\n",
    "\n",
    "# Ordenar da maior colinearidade para a menor\n",
    "vif_table = vif_table.sort_values(by=\"VIF\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Tabela de VIF (antes da exclusão):\")\n",
    "print(vif_table)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Identificar variáveis com VIF > 10 e removê-las\n",
    "# -------------------------------------------------------------------\n",
    "limite_vif = 10  # critério da sua anotação\n",
    "\n",
    "vars_alto_vif = vif_table.loc[vif_table[\"VIF\"] > limite_vif, \"variavel\"].tolist()\n",
    "\n",
    "print(\"\\nVariáveis com VIF > 10 (candidatas à exclusão):\")\n",
    "print(vars_alto_vif)\n",
    "\n",
    "# Criar um novo DataFrame SEM essas variáveis colineares\n",
    "df_sem_colinear = df.drop(columns=vars_alto_vif)\n",
    "\n",
    "print(\"\\nColunas finais em df_sem_colinear (após remover VIF > 10):\")\n",
    "print(df_sem_colinear.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8766bd9",
   "metadata": {},
   "source": [
    "## Retirar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c6be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9877f92",
   "metadata": {},
   "source": [
    "## Outliers - Método IQR e 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c664e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do df original:\n",
      "    Ano        Mes  Dengue  Zika  Chik  LeishVis  LeishTeg  LeishT  Precipt  \\\n",
      "0  2014    Janeiro    2901   NaN   NaN        15        31      46   138.90   \n",
      "1  2014  Fevereiro   10196   NaN   NaN        20        32      52   139.67   \n",
      "2  2014      Marco   29647   NaN   NaN        18        29      47   150.00   \n",
      "3  2014      Abril   85767   NaN   NaN        20        22      42   103.92   \n",
      "4  2014       Maio   62901   NaN   NaN        15        16      31    57.20   \n",
      "\n",
      "   AvgTemp  MaxTemp  MinTemp  AvgHumid  AvgWin  Season Season2  \n",
      "0    25.12    25.86    24.41     64.82    1.56  Summer     Wet  \n",
      "1    25.79    26.49    25.10     58.32    1.74  Summer     Wet  \n",
      "2    23.86    24.47    23.23     70.44    1.74  Summer     Wet  \n",
      "3    22.12    22.69    21.59     74.90    1.49    Fall     Dry  \n",
      "4    19.72    20.28    19.18     70.97    1.44    Fall     Dry   \n",
      "\n",
      "Resumo das colunas:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132 entries, 0 to 131\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Ano       132 non-null    int64  \n",
      " 1   Mes       132 non-null    object \n",
      " 2   Dengue    132 non-null    int64  \n",
      " 3   Zika      108 non-null    float64\n",
      " 4   Chik      96 non-null     float64\n",
      " 5   LeishVis  132 non-null    int64  \n",
      " 6   LeishTeg  132 non-null    int64  \n",
      " 7   LeishT    132 non-null    int64  \n",
      " 8   Precipt   132 non-null    float64\n",
      " 9   AvgTemp   132 non-null    float64\n",
      " 10  MaxTemp   132 non-null    float64\n",
      " 11  MinTemp   132 non-null    float64\n",
      " 12  AvgHumid  132 non-null    float64\n",
      " 13  AvgWin    132 non-null    float64\n",
      " 14  Season    132 non-null    object \n",
      " 15  Season2   132 non-null    object \n",
      "dtypes: float64(8), int64(5), object(3)\n",
      "memory usage: 16.6+ KB\n",
      "None \n",
      "\n",
      "Colunas após pré-tratamento (df):\n",
      "Index(['Dengue', 'Zika', 'Chik', 'LeishVis', 'LeishTeg', 'LeishT', 'Precipt',\n",
      "       'AvgTemp', 'AvgHumid', 'AvgWin', 'Season', 'Season2'],\n",
      "      dtype='object') \n",
      "\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: Dengue ===\n",
      "Total de observações para Dengue: 132\n",
      "Número de outliers detectados: 12\n",
      "Outliers de Dengue salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_Dengue_IQR.csv\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: Zika ===\n",
      "Total de observações para Zika: 108\n",
      "Número de outliers detectados: 11\n",
      "Outliers de Zika salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_Zika_IQR.csv\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: Chik ===\n",
      "Total de observações para Chik: 96\n",
      "Número de outliers detectados: 13\n",
      "Outliers de Chik salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_Chik_IQR.csv\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: LeishVis ===\n",
      "Total de observações para LeishVis: 132\n",
      "Número de outliers detectados: 4\n",
      "Outliers de LeishVis salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_LeishVis_IQR.csv\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: LeishTeg ===\n",
      "Total de observações para LeishTeg: 132\n",
      "Número de outliers detectados: 12\n",
      "Outliers de LeishTeg salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_LeishTeg_IQR.csv\n",
      "\n",
      "=== Avaliando outliers (IQR por mês) para: LeishT ===\n",
      "Total de observações para LeishT: 132\n",
      "Número de outliers detectados: 7\n",
      "Outliers de LeishT salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF\\outliers_LeishT_IQR.csv\n",
      "\n",
      "Resumo geral de outliers por doença (IQR):\n",
      "     doenca  n_total  n_outliers\n",
      "0    Dengue      132          12\n",
      "1      Zika      108          11\n",
      "2      Chik       96          13\n",
      "3  LeishVis      132           4\n",
      "4  LeishTeg      132          12\n",
      "5    LeishT      132           7\n",
      "\n",
      "Linhas totais em df_out: 132\n",
      "Linhas após remover outliers (IQR por mês): 94\n",
      "\n",
      "Colunas de df_iqr_sem_outliers:\n",
      "Index(['Dengue', 'Zika', 'Chik', 'LeishVis', 'LeishTeg', 'LeishT', 'Precipt',\n",
      "       'AvgTemp', 'AvgHumid', 'AvgWin', 'Season', 'Season2'],\n",
      "      dtype='object') \n",
      "\n",
      "\n",
      "Limiares de 'surto extremo' por doença (p99):\n",
      "     doenca        p99       max\n",
      "0    Dengue  528678.58  619390.0\n",
      "1      Zika    2442.17    2874.0\n",
      "2      Chik    7486.15    8154.0\n",
      "3  LeishVis      21.00      22.0\n",
      "4  LeishTeg      47.69      54.0\n",
      "5    LeishT      62.07      66.0\n",
      "\n",
      "Linhas totais em df_thresh: 132\n",
      "Linhas após remover surtos extremos (p99): 123\n",
      "\n",
      "Arquivo de limiares salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\limiares_por_doenca_p99.csv\n",
      "Dataset sem surtos extremos salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\Dataset_sem_extremos_p99.csv\n",
      "Outliers de Dengue salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_Dengue_p99.csv\n",
      "Outliers de Zika salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_Zika_p99.csv\n",
      "Outliers de Chik salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_Chik_p99.csv\n",
      "Outliers de LeishVis salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_LeishVis_p99.csv\n",
      "Outliers de LeishTeg salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_LeishTeg_p99.csv\n",
      "Outliers de LeishT salvos em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Outliers_RF_p99\\outliers_LeishT_p99.csv\n",
      "\n",
      "Shape de df_p99_sem_extremos (sem flags *_extremo): (123, 12)\n",
      "Colunas de df_p99_sem_extremos:\n",
      "Index(['Dengue', 'Zika', 'Chik', 'LeishVis', 'LeishTeg', 'LeishT', 'Precipt',\n",
      "       'AvgTemp', 'AvgHumid', 'AvgWin', 'Season', 'Season2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# 0) IMPORTS E CAMINHOS\n",
    "# =======================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho da pasta do projeto (mesmo que você vem usando)\n",
    "base_path = Path(r\"C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\")\n",
    "csv_path = base_path / \"Dataset_Modelos_Computacionais_clean.csv\"\n",
    "\n",
    "# =======================================\n",
    "# 1) LEITURA DO CSV E PRÉ-TRATAMENTO BÁSICO\n",
    "#    - cria coluna Data\n",
    "#    - usa Data como índice\n",
    "#    - remove Ano, Mes, MesNum, MinTemp, MaxTemp\n",
    "# =======================================\n",
    "\n",
    "# Leitura\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# (Opcional) olhar um pouco os dados\n",
    "print(\"Primeiras linhas do df original:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"Resumo das colunas:\")\n",
    "print(df.info(), \"\\n\")\n",
    "\n",
    "# Map de meses em português -> número\n",
    "mes_map = {\n",
    "    \"Janeiro\": 1,\n",
    "    \"Fevereiro\": 2,\n",
    "    \"Marco\": 3,\n",
    "    \"Março\": 3,  # caso apareça com acento\n",
    "    \"Abril\": 4,\n",
    "    \"Maio\": 5,\n",
    "    \"Junho\": 6,\n",
    "    \"Julho\": 7,\n",
    "    \"Agosto\": 8,\n",
    "    \"Setembro\": 9,\n",
    "    \"Outubro\": 10,\n",
    "    \"Novembro\": 11,\n",
    "    \"Dezembro\": 12\n",
    "}\n",
    "\n",
    "# Criar MesNum e coluna Data\n",
    "df[\"MesNum\"] = df[\"Mes\"].map(mes_map)\n",
    "df[\"Data\"] = pd.to_datetime(dict(year=df[\"Ano\"], month=df[\"MesNum\"], day=1))\n",
    "\n",
    "# Usar Data como índice temporal\n",
    "df = df.set_index(\"Data\").sort_index()\n",
    "\n",
    "# Remover colunas que NÃO queremos como preditoras\n",
    "df = df.drop(columns=[\"Ano\", \"Mes\", \"MesNum\", \"MinTemp\", \"MaxTemp\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Colunas após pré-tratamento (df):\")\n",
    "print(df.columns, \"\\n\")\n",
    "\n",
    "# =======================================\n",
    "# 2) OUTLIERS POR IQR (POR MÊS)\n",
    "#    -> df_iqr_sem_outliers\n",
    "#    + CSVs em pasta Outliers_RF\n",
    "# =======================================\n",
    "\n",
    "# Copia de trabalho\n",
    "df_out = df.copy()\n",
    "df_out.index = pd.to_datetime(df_out.index)\n",
    "\n",
    "# Coluna explícita de Data para exportar\n",
    "df_out[\"Data\"] = df_out.index\n",
    "\n",
    "# Mês do ano (1–12) e ano (pra análise IQR e CSV)\n",
    "df_out[\"Mes_do_ano\"] = df_out[\"Data\"].dt.month\n",
    "df_out[\"Ano\"] = df_out[\"Data\"].dt.year\n",
    "\n",
    "# Lista de doenças\n",
    "disease_cols = [\"Dengue\", \"Zika\", \"Chik\", \"LeishVis\", \"LeishTeg\", \"LeishT\"]\n",
    "\n",
    "# Pasta para salvar os CSVs de outliers IQR\n",
    "out_dir_iqr = base_path / \"Outliers_RF\"\n",
    "out_dir_iqr.mkdir(exist_ok=True)\n",
    "\n",
    "resumo_outliers = []\n",
    "\n",
    "for col in disease_cols:\n",
    "    if col not in df_out.columns:\n",
    "        print(f\"[AVISO] {col} não está no dataframe. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Avaliando outliers (IQR por mês) para: {col} ===\")\n",
    "\n",
    "    sub = df_out[[\"Data\", \"Ano\", \"Mes_do_ano\", col]].copy()\n",
    "    sub = sub.dropna(subset=[col])\n",
    "\n",
    "    if sub.empty:\n",
    "        print(f\"[AVISO] {col} só tem NaN. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    # Q1, Q3 e IQR por mês do ano\n",
    "    grupo = sub.groupby(\"Mes_do_ano\")[col]\n",
    "    q1 = grupo.quantile(0.25)\n",
    "    q3 = grupo.quantile(0.75)\n",
    "\n",
    "    sub = sub.join(q1.rename(\"Q1\"), on=\"Mes_do_ano\")\n",
    "    sub = sub.join(q3.rename(\"Q3\"), on=\"Mes_do_ano\")\n",
    "    sub[\"IQR\"] = sub[\"Q3\"] - sub[\"Q1\"]\n",
    "\n",
    "    sub[\"Limite_inferior\"] = sub[\"Q1\"] - 1.5 * sub[\"IQR\"]\n",
    "    sub[\"Limite_superior\"] = sub[\"Q3\"] + 1.5 * sub[\"IQR\"]\n",
    "\n",
    "    sub[\"is_outlier\"] = (sub[col] < sub[\"Limite_inferior\"]) | (sub[col] > sub[\"Limite_superior\"])\n",
    "\n",
    "    outliers = sub[sub[\"is_outlier\"]].copy()\n",
    "\n",
    "    print(f\"Total de observações para {col}: {len(sub)}\")\n",
    "    print(f\"Número de outliers detectados: {len(outliers)}\")\n",
    "\n",
    "    resumo_outliers.append({\n",
    "        \"doenca\": col,\n",
    "        \"n_total\": len(sub),\n",
    "        \"n_outliers\": len(outliers)\n",
    "    })\n",
    "\n",
    "    # salvar CSV só de outliers dessa doença\n",
    "    if len(outliers) > 0:\n",
    "        cols_salvar = [\n",
    "            \"Data\", \"Ano\", \"Mes_do_ano\", col,\n",
    "            \"Q1\", \"Q3\", \"Limite_inferior\", \"Limite_superior\", \"is_outlier\"\n",
    "        ]\n",
    "        out_csv_path = out_dir_iqr / f\"outliers_{col}_IQR.csv\"\n",
    "        outliers[cols_salvar].to_csv(out_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Outliers de {col} salvos em: {out_csv_path}\")\n",
    "    else:\n",
    "        print(f\"Nenhum outlier detectado para {col} com esse critério.\")\n",
    "\n",
    "    # Escrever flag de outlier de volta no df_out (alinhando por Data)\n",
    "    flag_series = sub.set_index(\"Data\")[\"is_outlier\"]\n",
    "    df_out[f\"{col}_outlier_IQR\"] = df_out.index.isin(flag_series[flag_series].index)\n",
    "\n",
    "# Resumo geral IQR\n",
    "resumo_iqr_df = pd.DataFrame(resumo_outliers)\n",
    "print(\"\\nResumo geral de outliers por doença (IQR):\")\n",
    "print(resumo_iqr_df)\n",
    "\n",
    "# Construir df_iqr_sem_outliers (remover qualquer linha com outlier em qualquer doença)\n",
    "iqr_flag_cols = [c for c in df_out.columns if c.endswith(\"_outlier_IQR\")]\n",
    "\n",
    "if len(iqr_flag_cols) > 0:\n",
    "    mask_any_iqr = df_out[iqr_flag_cols].any(axis=1)\n",
    "    df_iqr_sem_outliers = df_out[~mask_any_iqr].copy()\n",
    "else:\n",
    "    df_iqr_sem_outliers = df_out.copy()\n",
    "\n",
    "print(\"\\nLinhas totais em df_out:\", len(df_out))\n",
    "print(\"Linhas após remover outliers (IQR por mês):\", len(df_iqr_sem_outliers))\n",
    "\n",
    "# Limpar colunas auxiliares do df_iqr_sem_outliers para modelagem\n",
    "df_iqr_sem_outliers = df_iqr_sem_outliers.drop(\n",
    "    columns=iqr_flag_cols + [\"Mes_do_ano\", \"Ano\", \"Data\"],\n",
    "    errors=\"ignore\"\n",
    ")\n",
    "\n",
    "print(\"\\nColunas de df_iqr_sem_outliers:\")\n",
    "print(df_iqr_sem_outliers.columns, \"\\n\")\n",
    "\n",
    "# =======================================\n",
    "# 3) OUTLIERS \"EXTREMOS\" POR PERCENTIL GLOBAL (p99)\n",
    "#    -> df_p99_sem_extremos\n",
    "#    + pasta Outliers_RF_p99\n",
    "# =======================================\n",
    "\n",
    "df_thresh = df.copy()\n",
    "df_thresh.index = pd.to_datetime(df_thresh.index)\n",
    "\n",
    "percentile_cutoff = 0.99  # 99º percentil\n",
    "thresholds = []\n",
    "\n",
    "for col in disease_cols:\n",
    "    if col not in df_thresh.columns:\n",
    "        print(f\"[AVISO] {col} não está no dataframe. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    s = df_thresh[col].dropna()\n",
    "\n",
    "    if s.empty:\n",
    "        print(f\"[AVISO] {col} só tem NaN. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    # X: valor acima do qual vamos considerar \"surto extremo\"\n",
    "    X = s.quantile(percentile_cutoff)\n",
    "\n",
    "    thresholds.append({\n",
    "        \"doenca\": col,\n",
    "        f\"p{int(percentile_cutoff*100)}\": X,\n",
    "        \"max\": s.max()\n",
    "    })\n",
    "\n",
    "    # cria uma flag de \"surto extremo\" para essa doença\n",
    "    df_thresh[f\"{col}_extremo\"] = df_thresh[col] > X\n",
    "\n",
    "# tabela com cutoffs por doença\n",
    "thresholds_df = pd.DataFrame(thresholds)\n",
    "print(\"\\nLimiares de 'surto extremo' por doença (p99):\")\n",
    "print(thresholds_df)\n",
    "\n",
    "# construir df_sem_extremos removendo qualquer linha com *_extremo = True\n",
    "extreme_flag_cols = [c for c in df_thresh.columns if c.endswith(\"_extremo\")]\n",
    "\n",
    "if len(extreme_flag_cols) > 0:\n",
    "    mask_any_extreme = df_thresh[extreme_flag_cols].any(axis=1)\n",
    "    df_sem_extremos = df_thresh[~mask_any_extreme].copy()\n",
    "else:\n",
    "    df_sem_extremos = df_thresh.copy()\n",
    "\n",
    "print(\"\\nLinhas totais em df_thresh:\", len(df_thresh))\n",
    "print(\"Linhas após remover surtos extremos (p99):\", len(df_sem_extremos))\n",
    "\n",
    "# CRIAR PASTA E SALVAR CSVs DO P99\n",
    "out_dir_percentil = base_path / f\"Outliers_RF_p{int(percentile_cutoff*100)}\"\n",
    "out_dir_percentil.mkdir(exist_ok=True)\n",
    "\n",
    "# 1) salvar limiares por doença\n",
    "thresholds_csv_path = out_dir_percentil / f\"limiares_por_doenca_p{int(percentile_cutoff*100)}.csv\"\n",
    "thresholds_df.to_csv(thresholds_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nArquivo de limiares salvo em: {thresholds_csv_path}\")\n",
    "\n",
    "# 2) salvar dataset sem surtos extremos (incluindo flags *_extremo)\n",
    "dataset_sem_extremos_path = out_dir_percentil / f\"Dataset_sem_extremos_p{int(percentile_cutoff*100)}.csv\"\n",
    "df_sem_extremos.to_csv(dataset_sem_extremos_path, encoding=\"utf-8-sig\", index=True)\n",
    "print(f\"Dataset sem surtos extremos salvo em: {dataset_sem_extremos_path}\")\n",
    "\n",
    "# 3) salvar CSV de outliers por doença\n",
    "df_export = df_thresh.copy()\n",
    "df_export[\"Data\"] = df_export.index\n",
    "\n",
    "for col in disease_cols:\n",
    "    flag_col = f\"{col}_extremo\"\n",
    "    if flag_col not in df_export.columns:\n",
    "        continue\n",
    "\n",
    "    outliers_col = df_export[df_export[flag_col]].copy()\n",
    "    if outliers_col.empty:\n",
    "        print(f\"Nenhum surto extremo para {col} com p{int(percentile_cutoff*100)}.\")\n",
    "        continue\n",
    "\n",
    "    cols_salvar = [\"Data\", col, flag_col]\n",
    "    out_csv_path = out_dir_percentil / f\"outliers_{col}_p{int(percentile_cutoff*100)}.csv\"\n",
    "    outliers_col[cols_salvar].to_csv(out_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"Outliers de {col} salvos em: {out_csv_path}\")\n",
    "\n",
    "# 4) DataFrame final para usar nos modelos (sem flags *_extremo)\n",
    "df_p99_sem_extremos = df_sem_extremos.drop(columns=extreme_flag_cols + [\"Data\"], errors=\"ignore\")\n",
    "\n",
    "print(\"\\nShape de df_p99_sem_extremos (sem flags *_extremo):\", df_p99_sem_extremos.shape)\n",
    "print(\"Colunas de df_p99_sem_extremos:\")\n",
    "print(df_p99_sem_extremos.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb1125",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae8eeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# IMPORTS E CAMINHO BASE\n",
    "# =====================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0bd43",
   "metadata": {},
   "source": [
    "## Random Forest - Todos os modelos - CORRETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo1-base] Dengue -> MAE=27325.5807  MSE=2515575810.8887  R²=-2.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000024\n",
      "[Modelo1-base] Zika -> MAE=152.3936  MSE=99258.7818  R²=-1.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000036\n",
      "[Modelo1-base] Chik -> MAE=646.7904  MSE=750683.5240  R²=-0.5832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo1-base] LeishVis -> MAE=3.7083  MSE=20.4997  R²=0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo1-base] LeishTeg -> MAE=7.9560  MSE=96.7060  R²=-0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-base] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo1-base] LeishT -> MAE=9.3871  MSE=133.7414  R²=-0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo1-base) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo1_base\\resultados_base.csv\n",
      "\n",
      "=== [Modelo2-base] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo2-base] Dengue - treino: 99 pts, teste: 33 pts\n",
      "[Modelo2-base] Dengue -> MAE=70419.0249  MSE=26318321862.1203  R²=-0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-base] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000024\n",
      "[Modelo2-base] Zika - treino: 81 pts, teste: 27 pts\n",
      "[Modelo2-base] Zika -> MAE=89.6188  MSE=12974.7192  R²=-1.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-base] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000036\n",
      "[Modelo2-base] Chik - treino: 72 pts, teste: 24 pts\n",
      "[Modelo2-base] Chik -> MAE=1374.9619  MSE=3702720.5882  R²=-0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-base] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo2-base] LeishVis - treino: 99 pts, teste: 33 pts\n",
      "[Modelo2-base] LeishVis -> MAE=4.9334  MSE=32.8073  R²=-1.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-base] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo2-base] LeishTeg - treino: 99 pts, teste: 33 pts\n",
      "[Modelo2-base] LeishTeg -> MAE=6.9469  MSE=74.6595  R²=-0.4842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-base] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo2-base] LeishT - treino: 99 pts, teste: 33 pts\n",
      "[Modelo2-base] LeishT -> MAE=10.8937  MSE=166.9638  R²=-1.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo2-base) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo2_base_temporal\\resultados_base_temporal.csv\n",
      "\n",
      "=== [Modelo3-base] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3-base] Dengue - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3-base] Dengue -> MAE=68033.1413  MSE=24817132952.3171  R²=-0.0553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-base] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000024\n",
      "[Modelo3-base] Zika - treino: 78 pts, teste: 27 pts\n",
      "[Modelo3-base] Zika -> MAE=124.7640  MSE=33408.5994  R²=-5.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-base] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000036\n",
      "[Modelo3-base] Chik - treino: 69 pts, teste: 24 pts\n",
      "[Modelo3-base] Chik -> MAE=1101.4305  MSE=2425162.6685  R²=-0.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-base] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3-base] LeishVis - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3-base] LeishVis -> MAE=4.1840  MSE=24.2750  R²=-0.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-base] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3-base] LeishTeg - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3-base] LeishTeg -> MAE=6.8355  MSE=66.2998  R²=-0.3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-base] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3-base] LeishT - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3-base] LeishT -> MAE=9.5541  MSE=126.9269  R²=-0.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3-base) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_base_temporal_lag\\resultados_base_temporal_lag.csv\n",
      "\n",
      "=== [Modelo3D-base] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3D-base] Dengue - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3D-base] Dengue -> MAE=63996.9852  MSE=22537990837.7609  R²=0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-base] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000024\n",
      "[Modelo3D-base] Zika - treino: 78 pts, teste: 27 pts\n",
      "[Modelo3D-base] Zika -> MAE=100.3273  MSE=17070.4884  R²=-2.4824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-base] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00.000000036\n",
      "[Modelo3D-base] Chik - treino: 69 pts, teste: 24 pts\n",
      "[Modelo3D-base] Chik -> MAE=878.6638  MSE=1748194.5316  R²=0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-base] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3D-base] LeishVis - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3D-base] LeishVis -> MAE=4.3662  MSE=26.2728  R²=-0.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-base] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3D-base] LeishTeg - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3D-base] LeishTeg -> MAE=6.7178  MSE=63.2647  R²=-0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-base] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 1970-01-01 00:00:00\n",
      "[Modelo3D-base] LeishT - treino: 96 pts, teste: 33 pts\n",
      "[Modelo3D-base] LeishT -> MAE=9.5833  MSE=126.0391  R²=-0.7649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3D-base) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_base_temporal_lag_domada\\resultados_base_temporal_lag_domada.csv\n",
      "\n",
      "=== [Modelo1-IQR] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-IQR] Dengue -> MAE=16166.8236  MSE=828470861.5289  R²=-0.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-IQR] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-07-01 00:00:00\n",
      "[Modelo1-IQR] Zika -> MAE=59.1787  MSE=4964.3233  R²=-0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-IQR] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-02-01 00:00:00\n",
      "[Modelo1-IQR] Chik -> MAE=235.7590  MSE=89942.9135  R²=-0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-IQR] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-IQR] LeishVis -> MAE=3.1916  MSE=14.7473  R²=-0.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-IQR] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-IQR] LeishTeg -> MAE=5.8137  MSE=55.8894  R²=-0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-IQR] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-IQR] LeishT -> MAE=6.3132  MSE=57.8090  R²=-0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo1-IQR) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo1_IQR\\resultados_IQR.csv\n",
      "\n",
      "=== [Modelo2-IQR] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-IQR] Dengue - treino: 70 pts, teste: 24 pts\n",
      "[Modelo2-IQR] Dengue -> MAE=20653.0214  MSE=1276402569.8282  R²=-0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-IQR] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-07-01 00:00:00\n",
      "[Modelo2-IQR] Zika - treino: 59 pts, teste: 20 pts\n",
      "[Modelo2-IQR] Zika -> MAE=48.2743  MSE=2832.7907  R²=-0.2588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-IQR] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-02-01 00:00:00\n",
      "[Modelo2-IQR] Chik - treino: 55 pts, teste: 19 pts\n",
      "[Modelo2-IQR] Chik -> MAE=509.8605  MSE=722598.3360  R²=-2.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-IQR] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-IQR] LeishVis - treino: 70 pts, teste: 24 pts\n",
      "[Modelo2-IQR] LeishVis -> MAE=3.7044  MSE=18.2898  R²=-0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-IQR] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-IQR] LeishTeg - treino: 70 pts, teste: 24 pts\n",
      "[Modelo2-IQR] LeishTeg -> MAE=6.1539  MSE=49.6277  R²=-0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-IQR] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-IQR] LeishT - treino: 70 pts, teste: 24 pts\n",
      "[Modelo2-IQR] LeishT -> MAE=7.8815  MSE=82.9510  R²=-0.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo2-IQR) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo2_IQR_temporal\\resultados_IQR_temporal.csv\n",
      "\n",
      "=== [Modelo3-IQR] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-IQR] Dengue - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3-IQR] Dengue -> MAE=20932.1577  MSE=1319316611.8170  R²=-0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-IQR] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-07-01 00:00:00\n",
      "[Modelo3-IQR] Zika - treino: 57 pts, teste: 19 pts\n",
      "[Modelo3-IQR] Zika -> MAE=25.8646  MSE=1098.1724  R²=0.3578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-IQR] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-02-01 00:00:00\n",
      "[Modelo3-IQR] Chik - treino: 53 pts, teste: 18 pts\n",
      "[Modelo3-IQR] Chik -> MAE=153.1481  MSE=50802.8451  R²=0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-IQR] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-IQR] LeishVis - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3-IQR] LeishVis -> MAE=3.2687  MSE=15.1608  R²=-0.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-IQR] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-IQR] LeishTeg - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3-IQR] LeishTeg -> MAE=6.0918  MSE=44.8205  R²=-0.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-IQR] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-IQR] LeishT - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3-IQR] LeishT -> MAE=7.4696  MSE=69.6677  R²=-0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3-IQR) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_IQR_temporal_lag\\resultados_IQR_temporal_lag.csv\n",
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-IQR] Dengue - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3D-IQR] Dengue -> MAE=20062.2053  MSE=1192072228.0403  R²=0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-07-01 00:00:00\n",
      "[Modelo3D-IQR] Zika - treino: 57 pts, teste: 19 pts\n",
      "[Modelo3D-IQR] Zika -> MAE=28.5530  MSE=1175.3902  R²=0.3126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-02-01 00:00:00\n",
      "[Modelo3D-IQR] Chik - treino: 53 pts, teste: 18 pts\n",
      "[Modelo3D-IQR] Chik -> MAE=184.9711  MSE=102092.0957  R²=0.5751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-IQR] LeishVis - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3D-IQR] LeishVis -> MAE=3.2587  MSE=15.3423  R²=-0.3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-IQR] LeishTeg - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3D-IQR] LeishTeg -> MAE=5.8853  MSE=40.6783  R²=0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-IQR] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-IQR] LeishT - treino: 68 pts, teste: 23 pts\n",
      "[Modelo3D-IQR] LeishT -> MAE=7.3450  MSE=67.7809  R²=-0.3502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3D-IQR) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_IQR_temporal_lag_domada\\resultados_IQR_temporal_lag_domada.csv\n",
      "\n",
      "=== [Modelo1-p99] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-p99] Dengue -> MAE=40691.1353  MSE=3830619011.0001  R²=-0.1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-p99] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-02-01 00:00:00\n",
      "[Modelo1-p99] Zika -> MAE=136.3850  MSE=105379.0697  R²=0.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-p99] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-01-01 00:00:00\n",
      "[Modelo1-p99] Chik -> MAE=742.1622  MSE=2237486.6083  R²=0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-p99] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-p99] LeishVis -> MAE=3.8897  MSE=22.7841  R²=-0.1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-p99] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-p99] LeishTeg -> MAE=8.0632  MSE=96.4297  R²=-0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo1-p99] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo1-p99] LeishT -> MAE=10.0038  MSE=151.4938  R²=-0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo1-p99) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo1_p99\\resultados_p99.csv\n",
      "\n",
      "=== [Modelo2-p99] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-p99] Dengue - treino: 92 pts, teste: 31 pts\n",
      "[Modelo2-p99] Dengue -> MAE=38174.8089  MSE=7112309989.5949  R²=-0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-p99] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-02-01 00:00:00\n",
      "[Modelo2-p99] Zika - treino: 75 pts, teste: 26 pts\n",
      "[Modelo2-p99] Zika -> MAE=84.2895  MSE=11275.9324  R²=-2.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-p99] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-01-01 00:00:00\n",
      "[Modelo2-p99] Chik - treino: 69 pts, teste: 23 pts\n",
      "[Modelo2-p99] Chik -> MAE=1134.2951  MSE=2427508.2263  R²=-1.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-p99] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-p99] LeishVis - treino: 92 pts, teste: 31 pts\n",
      "[Modelo2-p99] LeishVis -> MAE=4.5749  MSE=27.7184  R²=-1.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-p99] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-p99] LeishTeg - treino: 92 pts, teste: 31 pts\n",
      "[Modelo2-p99] LeishTeg -> MAE=7.1661  MSE=77.1542  R²=-0.4553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo2-p99] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo2-p99] LeishT - treino: 92 pts, teste: 31 pts\n",
      "[Modelo2-p99] LeishT -> MAE=10.1926  MSE=153.1550  R²=-1.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo2-p99) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo2_p99_temporal\\resultados_p99_temporal.csv\n",
      "\n",
      "=== [Modelo3-p99] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-p99] Dengue - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3-p99] Dengue -> MAE=32450.6121  MSE=6185669726.0598  R²=0.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-p99] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-02-01 00:00:00\n",
      "[Modelo3-p99] Zika - treino: 73 pts, teste: 25 pts\n",
      "[Modelo3-p99] Zika -> MAE=65.2429  MSE=6688.3622  R²=-1.1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-p99] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-01-01 00:00:00\n",
      "[Modelo3-p99] Chik - treino: 66 pts, teste: 23 pts\n",
      "[Modelo3-p99] Chik -> MAE=896.9437  MSE=1620191.2965  R²=-0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-p99] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-p99] LeishVis - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3-p99] LeishVis -> MAE=4.2597  MSE=25.9344  R²=-0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-p99] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-p99] LeishTeg - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3-p99] LeishTeg -> MAE=6.5597  MSE=62.8035  R²=-0.1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3-p99] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3-p99] LeishT - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3-p99] LeishT -> MAE=8.9500  MSE=112.5885  R²=-0.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3-p99) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_p99_temporal_lag\\resultados_p99_temporal_lag.csv\n",
      "\n",
      "=== [Modelo3D-p99] Doença alvo: Dengue ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-p99] Dengue - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3D-p99] Dengue -> MAE=32466.2929  MSE=6484776744.6911  R²=0.0796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-p99] Doença alvo: Zika ===\n",
      "Primeira data usada no modelo: 2016-02-01 00:00:00\n",
      "[Modelo3D-p99] Zika - treino: 73 pts, teste: 25 pts\n",
      "[Modelo3D-p99] Zika -> MAE=58.8567  MSE=4823.7915  R²=-0.5639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-p99] Doença alvo: Chik ===\n",
      "Primeira data usada no modelo: 2017-01-01 00:00:00\n",
      "[Modelo3D-p99] Chik - treino: 66 pts, teste: 23 pts\n",
      "[Modelo3D-p99] Chik -> MAE=757.7719  MSE=1422847.6595  R²=-0.3061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-p99] Doença alvo: LeishVis ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-p99] LeishVis - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3D-p99] LeishVis -> MAE=4.1403  MSE=24.2254  R²=-0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-p99] Doença alvo: LeishTeg ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-p99] LeishTeg - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3D-p99] LeishTeg -> MAE=6.6923  MSE=63.9800  R²=-0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo3D-p99] Doença alvo: LeishT ===\n",
      "Primeira data usada no modelo: 2014-01-01 00:00:00\n",
      "[Modelo3D-p99] LeishT - treino: 90 pts, teste: 30 pts\n",
      "[Modelo3D-p99] LeishT -> MAE=8.9090  MSE=115.7925  R²=-0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idolo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo de métricas (Modelo3D-p99) salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo3_p99_temporal_lag_domada\\resultados_p99_temporal_lag_domada.csv\n",
      "\n",
      "=== RESUMO GERAL DE TODOS OS MODELOS ===\n",
      "                    modelo                       descricao_modelo dataset  \\\n",
      "0             M1_aleatorio                     RF split aleatório    base   \n",
      "1             M1_aleatorio                     RF split aleatório    base   \n",
      "2             M1_aleatorio                     RF split aleatório    base   \n",
      "3             M1_aleatorio                     RF split aleatório    base   \n",
      "4             M1_aleatorio                     RF split aleatório    base   \n",
      "..                     ...                                    ...     ...   \n",
      "67  M3_temporal_lag_domada  RF temporal + lags (1–3 meses) domada     p99   \n",
      "68  M3_temporal_lag_domada  RF temporal + lags (1–3 meses) domada     p99   \n",
      "69  M3_temporal_lag_domada  RF temporal + lags (1–3 meses) domada     p99   \n",
      "70  M3_temporal_lag_domada  RF temporal + lags (1–3 meses) domada     p99   \n",
      "71  M3_temporal_lag_domada  RF temporal + lags (1–3 meses) domada     p99   \n",
      "\n",
      "      doenca                 primeira_data  n_treino  n_teste           MAE  \\\n",
      "0     Dengue 1970-01-01 00:00:00.000000000        99       33  27325.580702   \n",
      "1       Zika 1970-01-01 00:00:00.000000024        81       27    152.393616   \n",
      "2       Chik 1970-01-01 00:00:00.000000036        72       24    646.790415   \n",
      "3   LeishVis 1970-01-01 00:00:00.000000000        99       33      3.708284   \n",
      "4   LeishTeg 1970-01-01 00:00:00.000000000        99       33      7.956017   \n",
      "..       ...                           ...       ...      ...           ...   \n",
      "67      Zika 2016-02-01 00:00:00.000000000        73       25     58.856726   \n",
      "68      Chik 2017-01-01 00:00:00.000000000        66       23    757.771897   \n",
      "69  LeishVis 2014-01-01 00:00:00.000000000        90       30      4.140314   \n",
      "70  LeishTeg 2014-01-01 00:00:00.000000000        90       30      6.692270   \n",
      "71    LeishT 2014-01-01 00:00:00.000000000        90       30      8.908959   \n",
      "\n",
      "             MSE        R2  \n",
      "0   2.515576e+09 -2.246572  \n",
      "1   9.925878e+04 -1.110499  \n",
      "2   7.506835e+05 -0.583198  \n",
      "3   2.049967e+01  0.062877  \n",
      "4   9.670604e+01 -0.201543  \n",
      "..           ...       ...  \n",
      "67  4.823792e+03 -0.563891  \n",
      "68  1.422848e+06 -0.306137  \n",
      "69  2.422543e+01 -0.828488  \n",
      "70  6.398002e+01 -0.187527  \n",
      "71  1.157925e+02 -0.568036  \n",
      "\n",
      "[72 rows x 10 columns]\n",
      "\n",
      "Arquivo Excel com tabela final salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\Tabela_Final_RF_Modelos\\Tabela_Final_RF_Modelos.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Caminho base \n",
    "base_path = Path(r\"C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\")\n",
    "\n",
    "# =====================================================\n",
    "# LISTAS GLOBAIS\n",
    "# =====================================================\n",
    "possible_disease_cols = [\"Dengue\", \"Zika\", \"Chik\", \"LeishVis\", \"LeishTeg\", \"LeishT\"]\n",
    "climate_cols = [\"Precipt\", \"AvgTemp\", \"MaxTemp\", \"MinTemp\", \"AvgHumid\", \"AvgWin\"]  # só entram como lag se existirem\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# FUNÇÕES AUXILIARES: IMPORTÂNCIA E GRÁFICO 3 PLOTS\n",
    "# =====================================================\n",
    "\n",
    "def calcular_importancia_agregada(model, numeric_features, categorical_features):\n",
    "    rf = model.named_steps[\"rf\"]\n",
    "\n",
    "    cat_names = []\n",
    "    try:\n",
    "        ohe = model.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "        if len(categorical_features) > 0:\n",
    "            cat_names = list(ohe.get_feature_names_out(categorical_features))\n",
    "    except Exception:\n",
    "        cat_names = []\n",
    "\n",
    "    num_names = list(numeric_features)\n",
    "    all_feature_names = num_names + cat_names\n",
    "\n",
    "    importances = pd.Series(rf.feature_importances_, index=all_feature_names)\n",
    "\n",
    "    agg = {}\n",
    "    for feat, imp in importances.items():\n",
    "        if feat in cat_names:\n",
    "            base = feat.split(\"_\", 1)[0]  # ex: \"Season_Summer\" -> \"Season\"\n",
    "        else:\n",
    "            base = feat\n",
    "        agg[base] = agg.get(base, 0.0) + imp\n",
    "\n",
    "    agg_series = pd.Series(agg).sort_values(ascending=False)\n",
    "    return agg_series\n",
    "\n",
    "\n",
    "def fazer_grafico_3plots(\n",
    "    y_test, y_pred, agg_series,\n",
    "    mae, mse, r2,\n",
    "    target_col, descricao_dataset,\n",
    "    titulo_extra, file_path\n",
    "):\n",
    "    residuals = y_test - y_pred\n",
    "    top_10 = agg_series.head(10).sort_values(ascending=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(25, 8))\n",
    "\n",
    "    # Subplot 1: Real vs Previsto\n",
    "    ax1 = axes[0]\n",
    "    sns.scatterplot(x=y_test, y=y_pred, ax=ax1)\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], linestyle=\"--\")\n",
    "    ax1.set_xlabel(\"Casos reais\")\n",
    "    ax1.set_ylabel(\"Casos previstos\")\n",
    "    ax1.set_title(f\"Real vs Previsto — {target_col} {titulo_extra}\")\n",
    "\n",
    "    text_str = f\"MAE = {mae:.2f}\\nMSE = {mse:.2f}\\nR² = {r2:.3f}\"\n",
    "    ax1.text(\n",
    "        0.05, 0.95, text_str,\n",
    "        transform=ax1.transAxes,\n",
    "        va=\"top\"\n",
    "    )\n",
    "\n",
    "    # Subplot 2: Distribuição dos resíduos\n",
    "    ax2 = axes[1]\n",
    "    sns.histplot(residuals, bins=20, ax=ax2)\n",
    "    ax2.set_xlabel(\"Resíduos (Real − Previsto)\")\n",
    "    ax2.set_ylabel(\"Frequência\")\n",
    "    ax2.set_title(\"Distribuição dos Resíduos\")\n",
    "\n",
    "    # Subplot 3: Importância (Top 10)\n",
    "    ax3 = axes[2]\n",
    "    ax3.barh(top_10.index, top_10.values)\n",
    "    ax3.set_xlabel(\"Importância (agregada)\")\n",
    "    ax3.set_ylabel(\"Variáveis (originais)\")\n",
    "    ax3.set_title(\"Top 10 Variáveis Mais Importantes\")\n",
    "\n",
    "    fig.suptitle(f\"Random Forest — {target_col} [{descricao_dataset}] {titulo_extra}\", y=1.02, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(file_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# MODELO 1 – RF SPLIT ALEATÓRIO\n",
    "# =====================================================\n",
    "\n",
    "def rodar_rf_basico_para_df(df_input, output_folder_name, descricao_dataset):\n",
    "    df_model = df_input.copy()\n",
    "    df_model.index = pd.to_datetime(df_model.index)\n",
    "\n",
    "    # Remover colunas que não queremos como preditoras (só por segurança)\n",
    "    cols_to_drop = []\n",
    "    for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "        if c in df_model.columns:\n",
    "            cols_to_drop.append(c)\n",
    "\n",
    "    extra_drop = [c for c in df_model.columns\n",
    "                  if c.endswith(\"_outlier_IQR\") or c.endswith(\"_extremo\")]\n",
    "    cols_to_drop.extend(extra_drop)\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_model = df_model.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "    output_dir = base_path / output_folder_name\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for target_col in possible_disease_cols:\n",
    "        if target_col not in df_model.columns:\n",
    "            print(f\"[AVISO] {target_col} não encontrada em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        first_idx = df_model[target_col].first_valid_index()\n",
    "        if first_idx is None:\n",
    "            print(f\"[AVISO] {target_col} é toda NaN em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== [Modelo1-{descricao_dataset}] Doença alvo: {target_col} ===\")\n",
    "        print(f\"Primeira data usada no modelo: {first_idx}\")\n",
    "\n",
    "        df_target = df_model.loc[first_idx:].copy()\n",
    "\n",
    "        y = df_target[target_col]\n",
    "        X = df_target.drop(\n",
    "            columns=[c for c in possible_disease_cols if c in df_target.columns],\n",
    "            errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        mask_valid = y.notna() & ~X.isna().any(axis=1)\n",
    "        X = X[mask_valid]\n",
    "        y = y[mask_valid]\n",
    "\n",
    "        if len(X) < 10:\n",
    "            print(f\"[AVISO] Poucos dados para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "        preprocess = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.25, random_state=42\n",
    "        )\n",
    "\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"rf\", RandomForestRegressor(\n",
    "                n_estimators=999,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"[Modelo1-{descricao_dataset}] {target_col} -> MAE={mae:.4f}  MSE={mse:.4f}  R²={r2:.4f}\")\n",
    "\n",
    "        agg_series = calcular_importancia_agregada(model, numeric_features, categorical_features)\n",
    "\n",
    "        resultados.append({\n",
    "            \"modelo\": \"M1_aleatorio\",\n",
    "            \"descricao_modelo\": \"RF split aleatório\",\n",
    "            \"dataset\": descricao_dataset,\n",
    "            \"doenca\": target_col,\n",
    "            \"primeira_data\": first_idx,\n",
    "            \"n_treino\": len(X_train),\n",
    "            \"n_teste\": len(X_test),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "        fig_path = output_dir / f\"RF_{target_col}_3plots_{descricao_dataset}.png\"\n",
    "        fazer_grafico_3plots(\n",
    "            y_test, y_pred, agg_series,\n",
    "            mae, mse, r2,\n",
    "            target_col, descricao_dataset,\n",
    "            titulo_extra=\"(split aleatório)\",\n",
    "            file_path=fig_path\n",
    "        )\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_csv_path = output_dir / f\"resultados_{descricao_dataset}.csv\"\n",
    "    resultados_df.to_csv(resultados_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nResumo de métricas (Modelo1-{descricao_dataset}) salvo em: {resultados_csv_path}\")\n",
    "\n",
    "    return resultados_df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# MODELO 2 – RF COM SPLIT TEMPORAL\n",
    "# =====================================================\n",
    "\n",
    "def rodar_rf_temporal_para_df(df_input, output_folder_name, descricao_dataset):\n",
    "    df_model = df_input.copy()\n",
    "    df_model.index = pd.to_datetime(df_model.index)\n",
    "    df_model = df_model.sort_index()\n",
    "\n",
    "    cols_to_drop = []\n",
    "    for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "        if c in df_model.columns:\n",
    "            cols_to_drop.append(c)\n",
    "\n",
    "    extra_drop = [c for c in df_model.columns\n",
    "                  if c.endswith(\"_outlier_IQR\") or c.endswith(\"_extremo\")]\n",
    "    cols_to_drop.extend(extra_drop)\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_model = df_model.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "    output_dir = base_path / output_folder_name\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for target_col in possible_disease_cols:\n",
    "        if target_col not in df_model.columns:\n",
    "            print(f\"[AVISO] {target_col} não encontrada em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        first_idx = df_model[target_col].first_valid_index()\n",
    "        if first_idx is None:\n",
    "            print(f\"[AVISO] {target_col} é toda NaN em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== [Modelo2-{descricao_dataset}] Doença alvo: {target_col} ===\")\n",
    "        print(f\"Primeira data usada no modelo: {first_idx}\")\n",
    "\n",
    "        df_target = df_model.loc[first_idx:].copy()\n",
    "        df_target = df_target.sort_index()\n",
    "\n",
    "        y = df_target[target_col]\n",
    "        X = df_target.drop(\n",
    "            columns=[c for c in possible_disease_cols if c in df_target.columns],\n",
    "            errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        mask_valid = y.notna() & ~X.isna().any(axis=1)\n",
    "        X = X[mask_valid]\n",
    "        y = y[mask_valid]\n",
    "\n",
    "        if len(X) < 10:\n",
    "            print(f\"[AVISO] Poucos dados para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        n = len(X)\n",
    "        split_idx = int(n * 0.75)\n",
    "\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "        print(f\"[Modelo2-{descricao_dataset}] {target_col} - treino: {len(X_train)} pts, teste: {len(X_test)} pts\")\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "        preprocess = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )\n",
    "\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"rf\", RandomForestRegressor(\n",
    "                n_estimators=999,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"[Modelo2-{descricao_dataset}] {target_col} -> MAE={mae:.4f}  MSE={mse:.4f}  R²={r2:.4f}\")\n",
    "\n",
    "        agg_series = calcular_importancia_agregada(model, numeric_features, categorical_features)\n",
    "\n",
    "        resultados.append({\n",
    "            \"modelo\": \"M2_temporal\",\n",
    "            \"descricao_modelo\": \"RF split temporal\",\n",
    "            \"dataset\": descricao_dataset,\n",
    "            \"doenca\": target_col,\n",
    "            \"primeira_data\": first_idx,\n",
    "            \"n_treino\": len(X_train),\n",
    "            \"n_teste\": len(X_test),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "        fig_path = output_dir / f\"RF_{target_col}_3plots_{descricao_dataset}_temporal.png\"\n",
    "        fazer_grafico_3plots(\n",
    "            y_test, y_pred, agg_series,\n",
    "            mae, mse, r2,\n",
    "            target_col, descricao_dataset,\n",
    "            titulo_extra=\"(split temporal)\",\n",
    "            file_path=fig_path\n",
    "        )\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_csv_path = output_dir / f\"resultados_{descricao_dataset}_temporal.csv\"\n",
    "    resultados_df.to_csv(resultados_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nResumo de métricas (Modelo2-{descricao_dataset}) salvo em: {resultados_csv_path}\")\n",
    "\n",
    "    return resultados_df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# MODELO 3 – RF TEMPORAL + LAGS (1,2,3 MESES)\n",
    "# =====================================================\n",
    "\n",
    "def rodar_rf_temporal_lag_para_df(df_input, output_folder_name, descricao_dataset):\n",
    "    df_base = df_input.copy()\n",
    "    df_base.index = pd.to_datetime(df_base.index)\n",
    "    df_base = df_base.sort_index()\n",
    "\n",
    "    cols_to_drop = []\n",
    "    for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "        if c in df_base.columns:\n",
    "            cols_to_drop.append(c)\n",
    "\n",
    "    extra_drop = [c for c in df_base.columns\n",
    "                  if c.endswith(\"_outlier_IQR\") or c.endswith(\"_extremo\")]\n",
    "    cols_to_drop.extend(extra_drop)\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_base = df_base.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "    output_dir = base_path / output_folder_name\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for target_col in possible_disease_cols:\n",
    "        if target_col not in df_base.columns:\n",
    "            print(f\"[AVISO] {target_col} não encontrada em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        first_idx = df_base[target_col].first_valid_index()\n",
    "        if first_idx is None:\n",
    "            print(f\"[AVISO] {target_col} é toda NaN em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== [Modelo3-{descricao_dataset}] Doença alvo: {target_col} ===\")\n",
    "        print(f\"Primeira data usada no modelo: {first_idx}\")\n",
    "\n",
    "        df_target = df_base.loc[first_idx:].copy()\n",
    "        df_target = df_target.sort_index()\n",
    "\n",
    "        # criar lags\n",
    "        df_lag = df_target.copy()\n",
    "        for lag in [1, 2, 3]:\n",
    "            for col in climate_cols:\n",
    "                if col in df_lag.columns:\n",
    "                    df_lag[f\"{col}_lag{lag}\"] = df_lag[col].shift(lag)\n",
    "\n",
    "        lag_cols = [f\"{col}_lag{lag}\" for col in climate_cols for lag in [1, 2, 3]\n",
    "                    if f\"{col}_lag{lag}\" in df_lag.columns]\n",
    "\n",
    "        if len(lag_cols) == 0:\n",
    "            print(f\"[AVISO] Nenhuma coluna de lag criada para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        df_lag = df_lag.dropna(subset=lag_cols)\n",
    "\n",
    "        if len(df_lag) < 10:\n",
    "            print(f\"[AVISO] Poucos dados após lags para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        if target_col not in df_lag.columns:\n",
    "            print(f\"[AVISO] {target_col} sumiu após lags em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        y = df_lag[target_col]\n",
    "        X = df_lag.drop(\n",
    "            columns=[c for c in possible_disease_cols if c in df_lag.columns],\n",
    "            errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "            if c in X.columns:\n",
    "                X = X.drop(columns=[c])\n",
    "\n",
    "        mask_valid = y.notna() & ~X.isna().any(axis=1)\n",
    "        X = X[mask_valid]\n",
    "        y = y[mask_valid]\n",
    "\n",
    "        if len(X) < 10:\n",
    "            print(f\"[AVISO] Poucos dados válidos para {target_col} em {descricao_dataset} após limpeza. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        n = len(X)\n",
    "        split_idx = int(n * 0.75)\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "        print(f\"[Modelo3-{descricao_dataset}] {target_col} - treino: {len(X_train)} pts, teste: {len(X_test)} pts\")\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "        preprocess = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )\n",
    "\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"rf\", RandomForestRegressor(\n",
    "                n_estimators=999,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"[Modelo3-{descricao_dataset}] {target_col} -> MAE={mae:.4f}  MSE={mse:.4f}  R²={r2:.4f}\")\n",
    "\n",
    "        agg_series = calcular_importancia_agregada(model, numeric_features, categorical_features)\n",
    "\n",
    "        resultados.append({\n",
    "            \"modelo\": \"M3_temporal_lag\",\n",
    "            \"descricao_modelo\": \"RF temporal + lags (1–3 meses)\",\n",
    "            \"dataset\": descricao_dataset,\n",
    "            \"doenca\": target_col,\n",
    "            \"primeira_data\": first_idx,\n",
    "            \"n_treino\": len(X_train),\n",
    "            \"n_teste\": len(X_test),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "        fig_path = output_dir / f\"RF_{target_col}_3plots_{descricao_dataset}_temporal_lag.png\"\n",
    "        fazer_grafico_3plots(\n",
    "            y_test, y_pred, agg_series,\n",
    "            mae, mse, r2,\n",
    "            target_col, descricao_dataset,\n",
    "            titulo_extra=\"(temporal + lags)\",\n",
    "            file_path=fig_path\n",
    "        )\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_csv_path = output_dir / f\"resultados_{descricao_dataset}_temporal_lag.csv\"\n",
    "    resultados_df.to_csv(resultados_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nResumo de métricas (Modelo3-{descricao_dataset}) salvo em: {resultados_csv_path}\")\n",
    "\n",
    "    return resultados_df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# MODELO 3 DOMADA – RF TEMPORAL + LAGS + RESTRIÇÕES\n",
    "# =====================================================\n",
    "\n",
    "def rodar_rf_temporal_lag_domada_para_df(df_input, output_folder_name, descricao_dataset):\n",
    "    df_base = df_input.copy()\n",
    "    df_base.index = pd.to_datetime(df_base.index)\n",
    "    df_base = df_base.sort_index()\n",
    "\n",
    "    cols_to_drop = []\n",
    "    for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "        if c in df_base.columns:\n",
    "            cols_to_drop.append(c)\n",
    "\n",
    "    extra_drop = [c for c in df_base.columns\n",
    "                  if c.endswith(\"_outlier_IQR\") or c.endswith(\"_extremo\")]\n",
    "    cols_to_drop.extend(extra_drop)\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_base = df_base.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "    output_dir = base_path / output_folder_name\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for target_col in possible_disease_cols:\n",
    "        if target_col not in df_base.columns:\n",
    "            print(f\"[AVISO] {target_col} não encontrada em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        first_idx = df_base[target_col].first_valid_index()\n",
    "        if first_idx is None:\n",
    "            print(f\"[AVISO] {target_col} é toda NaN em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== [Modelo3D-{descricao_dataset}] Doença alvo: {target_col} ===\")\n",
    "        print(f\"Primeira data usada no modelo: {first_idx}\")\n",
    "\n",
    "        df_target = df_base.loc[first_idx:].copy()\n",
    "        df_target = df_target.sort_index()\n",
    "\n",
    "        df_lag = df_target.copy()\n",
    "        for lag in [1, 2, 3]:\n",
    "            for col in climate_cols:\n",
    "                if col in df_lag.columns:\n",
    "                    df_lag[f\"{col}_lag{lag}\"] = df_lag[col].shift(lag)\n",
    "\n",
    "        lag_cols = [f\"{col}_lag{lag}\" for col in climate_cols for lag in [1, 2, 3]\n",
    "                    if f\"{col}_lag{lag}\" in df_lag.columns]\n",
    "\n",
    "        if len(lag_cols) == 0:\n",
    "            print(f\"[AVISO] Nenhuma coluna de lag criada para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        df_lag = df_lag.dropna(subset=lag_cols)\n",
    "\n",
    "        if len(df_lag) < 10:\n",
    "            print(f\"[AVISO] Poucos dados após lags para {target_col} em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        if target_col not in df_lag.columns:\n",
    "            print(f\"[AVISO] {target_col} sumiu após lags em {descricao_dataset}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        y = df_lag[target_col]\n",
    "        X = df_lag.drop(\n",
    "            columns=[c for c in possible_disease_cols if c in df_lag.columns],\n",
    "            errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "            if c in X.columns:\n",
    "                X = X.drop(columns=[c])\n",
    "\n",
    "        mask_valid = y.notna() & ~X.isna().any(axis=1)\n",
    "        X = X[mask_valid]\n",
    "        y = y[mask_valid]\n",
    "\n",
    "        if len(X) < 10:\n",
    "            print(f\"[AVISO] Poucos dados válidos para {target_col} em {descricao_dataset} após limpeza. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        n = len(X)\n",
    "        split_idx = int(n * 0.75)\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "        print(f\"[Modelo3D-{descricao_dataset}] {target_col} - treino: {len(X_train)} pts, teste: {len(X_test)} pts\")\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "        preprocess = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )\n",
    "\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"rf\", RandomForestRegressor(\n",
    "                n_estimators=500,\n",
    "                max_depth=5,\n",
    "                min_samples_leaf=3,\n",
    "                max_features=\"sqrt\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"[Modelo3D-{descricao_dataset}] {target_col} -> MAE={mae:.4f}  MSE={mse:.4f}  R²={r2:.4f}\")\n",
    "\n",
    "        agg_series = calcular_importancia_agregada(model, numeric_features, categorical_features)\n",
    "\n",
    "        resultados.append({\n",
    "            \"modelo\": \"M3_temporal_lag_domada\",\n",
    "            \"descricao_modelo\": \"RF temporal + lags (1–3 meses) domada\",\n",
    "            \"dataset\": descricao_dataset,\n",
    "            \"doenca\": target_col,\n",
    "            \"primeira_data\": first_idx,\n",
    "            \"n_treino\": len(X_train),\n",
    "            \"n_teste\": len(X_test),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "        fig_path = output_dir / f\"RF_{target_col}_3plots_{descricao_dataset}_temporal_lag_domada.png\"\n",
    "        fazer_grafico_3plots(\n",
    "            y_test, y_pred, agg_series,\n",
    "            mae, mse, r2,\n",
    "            target_col, descricao_dataset,\n",
    "            titulo_extra=\"(temporal + lags + domada)\",\n",
    "            file_path=fig_path\n",
    "        )\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_csv_path = output_dir / f\"resultados_{descricao_dataset}_temporal_lag_domada.csv\"\n",
    "    resultados_df.to_csv(resultados_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nResumo de métricas (Modelo3D-{descricao_dataset}) salvo em: {resultados_csv_path}\")\n",
    "\n",
    "    return resultados_df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# RODAR TODOS OS MODELOS PARA AS 3 BASES\n",
    "# =====================================================\n",
    "\n",
    "# ⚠️ Aqui assumo que df, df_iqr_sem_outliers, df_p99_sem_extremos já existem!\n",
    "\n",
    "bases = {\n",
    "    \"base\": df,\n",
    "    \"IQR\": df_iqr_sem_outliers,\n",
    "    \"p99\": df_p99_sem_extremos\n",
    "}\n",
    "\n",
    "resultados_M1 = []\n",
    "resultados_M2 = []\n",
    "resultados_M3 = []\n",
    "resultados_M3D = []\n",
    "\n",
    "for desc, df_base_modelo in bases.items():\n",
    "    # Modelo 1 – split aleatório\n",
    "    result_m1 = rodar_rf_basico_para_df(\n",
    "        df_base_modelo,\n",
    "        f\"RF_Modelo1_{desc}\",\n",
    "        desc\n",
    "    )\n",
    "    resultados_M1.append(result_m1)\n",
    "\n",
    "    # Modelo 2 – split temporal\n",
    "    result_m2 = rodar_rf_temporal_para_df(\n",
    "        df_base_modelo,\n",
    "        f\"RF_Modelo2_{desc}_temporal\",\n",
    "        desc\n",
    "    )\n",
    "    resultados_M2.append(result_m2)\n",
    "\n",
    "    # Modelo 3 – temporal + lags\n",
    "    result_m3 = rodar_rf_temporal_lag_para_df(\n",
    "        df_base_modelo,\n",
    "        f\"RF_Modelo3_{desc}_temporal_lag\",\n",
    "        desc\n",
    "    )\n",
    "    resultados_M3.append(result_m3)\n",
    "\n",
    "    # Modelo 3 DOMADA – temporal + lags + domada\n",
    "    result_m3d = rodar_rf_temporal_lag_domada_para_df(\n",
    "        df_base_modelo,\n",
    "        f\"RF_Modelo3_{desc}_temporal_lag_domada\",\n",
    "        desc\n",
    "    )\n",
    "    resultados_M3D.append(result_m3d)\n",
    "\n",
    "# Resumos combinados\n",
    "resumo_M1 = pd.concat(resultados_M1, ignore_index=True)\n",
    "resumo_M2 = pd.concat(resultados_M2, ignore_index=True)\n",
    "resumo_M3 = pd.concat(resultados_M3, ignore_index=True)\n",
    "resumo_M3D = pd.concat(resultados_M3D, ignore_index=True)\n",
    "\n",
    "resumo_geral = pd.concat([resumo_M1, resumo_M2, resumo_M3, resumo_M3D], ignore_index=True)\n",
    "\n",
    "print(\"\\n=== RESUMO GERAL DE TODOS OS MODELOS ===\")\n",
    "print(resumo_geral)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# GERAR EXCEL FINAL: UMA ABA POR DOENÇA\n",
    "# =====================================================\n",
    "\n",
    "# Pasta para a tabela final\n",
    "tabela_dir = base_path / \"Tabela_Final_RF_Modelos\"\n",
    "tabela_dir.mkdir(exist_ok=True)\n",
    "\n",
    "excel_path = tabela_dir / \"Tabela_Final_RF_Modelos.xlsx\"\n",
    "\n",
    "# Aqui uso engine=\"openpyxl\" para evitar erro de xlsxwriter\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    # uma aba por doença\n",
    "    for doenca in possible_disease_cols:\n",
    "        df_doenca = resumo_geral[resumo_geral[\"doenca\"] == doenca].copy()\n",
    "        if df_doenca.empty:\n",
    "            continue\n",
    "\n",
    "        # ordem das colunas (só usa as que existirem)\n",
    "        cols_order = [\n",
    "            \"modelo\",\n",
    "            \"descricao_modelo\",\n",
    "            \"dataset\",\n",
    "            \"doenca\",\n",
    "            \"primeira_data\",\n",
    "            \"n_treino\",\n",
    "            \"n_teste\",\n",
    "            \"MAE\",\n",
    "            \"MSE\",\n",
    "            \"R2\"\n",
    "        ]\n",
    "        existing_cols = [c for c in cols_order if c in df_doenca.columns]\n",
    "        df_doenca = df_doenca[existing_cols]\n",
    "\n",
    "        sheet_name = doenca[:31]  # limite de 31 caracteres no nome da aba do Excel\n",
    "        df_doenca.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # aba extra com tudo junto\n",
    "    resumo_geral.to_excel(writer, sheet_name=\"ResumoGeral\", index=False)\n",
    "\n",
    "print(f\"\\nArquivo Excel com tabela final salvo em: {excel_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ed045",
   "metadata": {},
   "source": [
    "## Classificando mês epidêmico vs Não epidêmico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0d1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a9b4d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Modelo4] Doença alvo: Dengue ===\n",
      "Primeira data usada: 1970-01-01 00:00:00\n",
      "Limiar (p75) para Dengue: 33840.00 casos\n",
      "Dengue: 33 meses epidêmicos (1) de 129 meses totais (25.6% positivos)\n",
      "Treino: 96 meses, Teste: 33 meses\n",
      "Melhor limiar para Dengue (Youden): 0.20\n",
      "  Sensibilidade: 0.846  Especificidade: 0.900  Acurácia: 0.879\n",
      "\n",
      "=== [Modelo4] Doença alvo: Zika ===\n",
      "Primeira data usada: 1970-01-01 00:00:00.000000024\n",
      "Limiar (p75) para Zika: 170.00 casos\n",
      "Zika: 27 meses epidêmicos (1) de 105 meses totais (25.7% positivos)\n",
      "Treino: 78 meses, Teste: 27 meses\n",
      "Melhor limiar para Zika (Youden): 0.60\n",
      "  Sensibilidade: 0.800  Especificidade: 0.955  Acurácia: 0.926\n",
      "\n",
      "=== [Modelo4] Doença alvo: Chik ===\n",
      "Primeira data usada: 1970-01-01 00:00:00.000000036\n",
      "Limiar (p75) para Chik: 912.00 casos\n",
      "Chik: 24 meses epidêmicos (1) de 93 meses totais (25.8% positivos)\n",
      "Treino: 69 meses, Teste: 24 meses\n",
      "Melhor limiar para Chik (Youden): 0.10\n",
      "  Sensibilidade: 0.647  Especificidade: 1.000  Acurácia: 0.750\n",
      "\n",
      "=== [Modelo4] Doença alvo: LeishVis ===\n",
      "Primeira data usada: 1970-01-01 00:00:00\n",
      "Limiar (p75) para LeishVis: 14.00 casos\n",
      "LeishVis: 34 meses epidêmicos (1) de 129 meses totais (26.4% positivos)\n",
      "Treino: 96 meses, Teste: 33 meses\n",
      "Melhor limiar para LeishVis (Youden): 0.20\n",
      "  Sensibilidade: 1.000  Especificidade: 0.267  Acurácia: 0.333\n",
      "\n",
      "=== [Modelo4] Doença alvo: LeishTeg ===\n",
      "Primeira data usada: 1970-01-01 00:00:00\n",
      "Limiar (p75) para LeishTeg: 34.00 casos\n",
      "LeishTeg: 33 meses epidêmicos (1) de 129 meses totais (25.6% positivos)\n",
      "Treino: 96 meses, Teste: 33 meses\n",
      "Melhor limiar para LeishTeg (Youden): 0.30\n",
      "  Sensibilidade: 0.800  Especificidade: 0.643  Acurácia: 0.667\n",
      "\n",
      "=== [Modelo4] Doença alvo: LeishT ===\n",
      "Primeira data usada: 1970-01-01 00:00:00\n",
      "Limiar (p75) para LeishT: 45.00 casos\n",
      "LeishT: 34 meses epidêmicos (1) de 129 meses totais (26.4% positivos)\n",
      "Treino: 96 meses, Teste: 33 meses\n",
      "Melhor limiar para LeishT (Youden): 0.30\n",
      "  Sensibilidade: 1.000  Especificidade: 0.581  Acurácia: 0.606\n",
      "\n",
      "=== RESUMO GERAL CLASSIFICAÇÃO EPIDÊMICO vs NÃO ===\n",
      "     doenca       AUC  best_threshold  accuracy_best  precision_best  \\\n",
      "0    Dengue  0.957692             0.2       0.878788        0.846154   \n",
      "1      Zika  0.918182             0.6       0.925926        0.800000   \n",
      "2      Chik  0.773109             0.1       0.750000        1.000000   \n",
      "3  LeishVis  0.577778             0.2       0.333333        0.120000   \n",
      "4  LeishTeg  0.635714             0.3       0.666667        0.285714   \n",
      "5    LeishT  0.774194             0.3       0.606061        0.133333   \n",
      "\n",
      "   recall_sensibilidade_best  especificidade_best   f1_best  n_treino  \\\n",
      "0                   0.846154             0.900000  0.846154        96   \n",
      "1                   0.800000             0.954545  0.800000        78   \n",
      "2                   0.647059             1.000000  0.785714        69   \n",
      "3                   1.000000             0.266667  0.214286        96   \n",
      "4                   0.800000             0.642857  0.421053        96   \n",
      "5                   1.000000             0.580645  0.235294        96   \n",
      "\n",
      "   n_teste  n_pos_treino  n_pos_teste  limiar_casos_percentil  \\\n",
      "0       33            20           13                    0.75   \n",
      "1       27            22            5                    0.75   \n",
      "2       24             7           17                    0.75   \n",
      "3       33            31            3                    0.75   \n",
      "4       33            28            5                    0.75   \n",
      "5       33            32            2                    0.75   \n",
      "\n",
      "   valor_limiar_casos  \n",
      "0             33840.0  \n",
      "1               170.0  \n",
      "2               912.0  \n",
      "3                14.0  \n",
      "4                34.0  \n",
      "5                45.0  \n",
      "\n",
      "Arquivo Excel de classificação salvo em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo4_Classificacao_Epidemico\\Tabela_Modelo4_Classificacao_Epidemico.xlsx\n",
      "Figuras (ROC e Matriz de Confusão) salvas em: C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\\RF_Modelo4_Classificacao_Epidemico\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# MODELO 4 – CLASSIFICAÇÃO: MÊS EPIDÊMICO vs NÃO\n",
    "# ==============================================\n",
    "# - Usa base original df (sem remover surtos extremos)\n",
    "# - Para cada doença em possible_disease_cols:\n",
    "#     - define limiar = p75 da série daquela doença (após first_valid_index)\n",
    "#     - y_bin = 1 se casos >= limiar, senão 0\n",
    "#     - X = clima + lags (1,2,3) + mês em sin/cos\n",
    "#     - split temporal (75% treino, 25% teste)\n",
    "#     - RandomForestClassifier \"domado\"\n",
    "#     - Gera:\n",
    "#         - curva ROC (png)\n",
    "#         - matriz de confusão para melhor limiar (png)\n",
    "#         - Excel com resumo + tabela de thresholds por doença\n",
    "# ==============================================\n",
    "\n",
    "# Caminho base (ajusta se precisar)\n",
    "base_path = Path(r\"C:\\Users\\idolo\\OneDrive\\Área de Trabalho\\Curso - Modelos Computacionais\\Projeto\")\n",
    "\n",
    "# Lista de doenças e variáveis climáticas (lags)\n",
    "possible_disease_cols = [\"Dengue\", \"Zika\", \"Chik\", \"LeishVis\", \"LeishTeg\", \"LeishT\"]\n",
    "climate_cols = [\"Precipt\", \"AvgTemp\", \"MaxTemp\", \"MinTemp\", \"AvgHumid\", \"AvgWin\"]  # só usa as que existirem\n",
    "\n",
    "# Percentil para definir \"mês epidêmico\"\n",
    "epidemic_percentile = 0.75  # p75\n",
    "\n",
    "# Pasta de saída para tudo desse modelo de classificação\n",
    "output_dir_class = base_path / \"RF_Modelo4_Classificacao_Epidemico\"\n",
    "output_dir_class.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def classificar_meses_epidemicos(\n",
    "    df_input,\n",
    "    target_cols=possible_disease_cols,\n",
    "    percentile_limiar=epidemic_percentile,\n",
    "    max_lag=3,\n",
    "    thresholds_list=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Roda RandomForestClassifier para prever se um mês é epidêmico (1) ou não (0),\n",
    "    para cada doença em target_cols, usando:\n",
    "      - base df_input\n",
    "      - lags (1..max_lag) das variáveis climáticas disponíveis\n",
    "      - mês em sin/cos (codificação cíclica)\n",
    "      - split temporal (75% / 25%)\n",
    "      - threshold sweep (ex.: 0.1, 0.2, ..., 0.9)\n",
    "    Retorna:\n",
    "      - resumo_df: uma linha por doença (AUC, melhor threshold, métricas no melhor threshold)\n",
    "      - thresholds_all_df: tabela com métricas por doença x threshold\n",
    "    \"\"\"\n",
    "\n",
    "    if thresholds_list is None:\n",
    "        thresholds_list = [round(t, 2) for t in np.arange(0.1, 1.0, 0.1)]  # 0.1, 0.2, ..., 0.9\n",
    "\n",
    "    # cópia de trabalho\n",
    "    df_base = df_input.copy()\n",
    "    df_base.index = pd.to_datetime(df_base.index)\n",
    "    df_base = df_base.sort_index()\n",
    "\n",
    "    # garantir que não tem colunas estranhas de tempo\n",
    "    cols_to_drop = []\n",
    "    for c in [\"Data\", \"Ano\", \"Mes\", \"MesNum\", \"Mes_do_ano\"]:\n",
    "        if c in df_base.columns:\n",
    "            cols_to_drop.append(c)\n",
    "\n",
    "    # se vierem flags de outlier por engano, também tira\n",
    "    extra_drop = [c for c in df_base.columns\n",
    "                  if c.endswith(\"_outlier_IQR\") or c.endswith(\"_extremo\")]\n",
    "    cols_to_drop.extend(extra_drop)\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_base = df_base.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "    resumo_linhas = []\n",
    "    thresholds_linhas = []\n",
    "\n",
    "    # Loop por doença\n",
    "    for target_col in target_cols:\n",
    "        if target_col not in df_base.columns:\n",
    "            print(f\"[AVISO] {target_col} não está em df. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # primeira data com valor não-nulo para essa doença\n",
    "        first_idx = df_base[target_col].first_valid_index()\n",
    "        if first_idx is None:\n",
    "            print(f\"[AVISO] {target_col} é toda NaN. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== [Modelo4] Doença alvo: {target_col} ===\")\n",
    "        print(f\"Primeira data usada: {first_idx}\")\n",
    "\n",
    "        # Subdataframe a partir do primeiro valor válido\n",
    "        df_target = df_base.loc[first_idx:].copy()\n",
    "        df_target = df_target.sort_index()\n",
    "\n",
    "        # criar mês do ano (1..12) a partir do índice e codificação cíclica\n",
    "        df_target[\"Mes_do_ano\"] = df_target.index.month\n",
    "        df_target[\"Mes_sin\"] = np.sin(2 * np.pi * (df_target[\"Mes_do_ano\"] - 1) / 12.0)\n",
    "        df_target[\"Mes_cos\"] = np.cos(2 * np.pi * (df_target[\"Mes_do_ano\"] - 1) / 12.0)\n",
    "\n",
    "        # criar lags das variáveis climáticas que existirem\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            for col in climate_cols:\n",
    "                if col in df_target.columns:\n",
    "                    df_target[f\"{col}_lag{lag}\"] = df_target[col].shift(lag)\n",
    "\n",
    "        # variável contínua de casos (para definir o limiar)\n",
    "        y_cont = df_target[target_col]\n",
    "\n",
    "        # remover as primeiras linhas que ficaram com NaN nos lags (onde necessário)\n",
    "        # vamos considerar como features todas as colunas climáticas + seus lags + Mes_sin/cos\n",
    "        # Primeiro, definimos quais colunas potenciais de X (sem tirar doenças ainda)\n",
    "        colunas_possiveis_X = list(df_target.columns)\n",
    "\n",
    "        # mas vamos tirar as próprias doenças (não podem ser preditoras)\n",
    "        for dcol in possible_disease_cols:\n",
    "            if dcol in colunas_possiveis_X:\n",
    "                colunas_possiveis_X.remove(dcol)\n",
    "\n",
    "        # vamos construir X preliminar\n",
    "        X_pre = df_target[colunas_possiveis_X].copy()\n",
    "\n",
    "        # Remover linhas com NaN em qualquer feature (principalmente por causa dos lags)\n",
    "        # e também garantir que y_cont não seja NaN nessas linhas\n",
    "        mask_valid = (~X_pre.isna().any(axis=1)) & y_cont.notna()\n",
    "        X_pre = X_pre[mask_valid]\n",
    "        y_cont_use = y_cont[mask_valid]\n",
    "\n",
    "        if len(X_pre) < 20:\n",
    "            print(f\"[AVISO] Muito poucos dados válidos para {target_col} após lags/limpeza. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Definir limiar de \"mês epidêmico\" (percentil da série dessa doença)\n",
    "        limiar = y_cont_use.quantile(percentile_limiar)\n",
    "        print(f\"Limiar (p{int(percentile_limiar*100)}) para {target_col}: {limiar:.2f} casos\")\n",
    "\n",
    "        # y binário\n",
    "        y_bin = (y_cont_use >= limiar).astype(int)\n",
    "\n",
    "        # Agora, X definitivo: remove qualquer resto de coluna que não queremos\n",
    "        X = X_pre.copy()\n",
    "\n",
    "        # garantir que doenças não estão em X (por segurança extra)\n",
    "        X = X.drop(columns=[c for c in possible_disease_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "        # tirar Mes_do_ano (já temos sin/cos)\n",
    "        X = X.drop(columns=[\"Mes_do_ano\"], errors=\"ignore\")\n",
    "\n",
    "        # conferência de classes\n",
    "        n_pos = int(y_bin.sum())\n",
    "        n_total = len(y_bin)\n",
    "        print(f\"{target_col}: {n_pos} meses epidêmicos (1) de {n_total} meses totais \"\n",
    "              f\"({n_pos/n_total:.1%} positivos)\")\n",
    "\n",
    "        # SPLIT TEMPORAL (75% / 25%)\n",
    "        n = len(X)\n",
    "        split_idx = int(n * 0.75)\n",
    "\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y_bin.iloc[:split_idx], y_bin.iloc[split_idx:]\n",
    "\n",
    "        print(f\"Treino: {len(X_train)} meses, Teste: {len(X_test)} meses\")\n",
    "\n",
    "        # precisa de pelo menos 1 positivo e 1 negativo em treino e teste\n",
    "        if y_train.nunique() < 2 or y_test.nunique() < 2:\n",
    "            print(f\"[AVISO] Conjunto de treino ou teste de {target_col} só tem uma classe.\"\n",
    "                  f\" ROC/AUC ficam indefinidos. Pulando classificação.\")\n",
    "            continue\n",
    "\n",
    "        # Detectar tipos de colunas\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "        preprocess = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )\n",
    "\n",
    "        # Random Forest Classifier \"domada\"\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"rf\", RandomForestClassifier(\n",
    "                n_estimators=500,\n",
    "                max_depth=5,\n",
    "                min_samples_leaf=3,\n",
    "                max_features=\"sqrt\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        # treinar e prever\n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # AUC geral (independe do threshold)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "        # Figura ROC\n",
    "        fig_roc, ax_roc = plt.subplots(figsize=(6, 5))\n",
    "        ax_roc.plot(fpr, tpr, label=f\"ROC (AUC = {auc:.3f})\")\n",
    "        ax_roc.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Aleatório\")\n",
    "        ax_roc.set_xlabel(\"Falso Positivo (1 - Especificidade)\")\n",
    "        ax_roc.set_ylabel(\"Verdadeiro Positivo (Sensibilidade)\")\n",
    "        ax_roc.set_title(f\"Curva ROC — {target_col}\")\n",
    "        ax_roc.legend(loc=\"lower right\")\n",
    "        fig_roc.tight_layout()\n",
    "\n",
    "        roc_path = output_dir_class / f\"ROC_{target_col}.png\"\n",
    "        fig_roc.savefig(roc_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig_roc)\n",
    "\n",
    "        # VARREDURA DE THRESHOLDS (0.1, 0.2, ..., 0.9)\n",
    "        best_thr = None\n",
    "        best_youden = -np.inf\n",
    "        best_metrics = None\n",
    "\n",
    "        for thr in thresholds_list:\n",
    "            y_pred_thr = (y_proba >= thr).astype(int)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred_thr)\n",
    "            prec = precision_score(y_test, y_pred_thr, zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred_thr, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred_thr, zero_division=0)\n",
    "\n",
    "            # matriz de confusão pra especificidade\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thr, labels=[0, 1]).ravel()\n",
    "            sens = rec\n",
    "            espec = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "\n",
    "            # Índice de Youden: sens + espec - 1\n",
    "            youden = sens + espec - 1 if np.isfinite(sens) and np.isfinite(espec) else -np.inf\n",
    "\n",
    "            thresholds_linhas.append({\n",
    "                \"doenca\": target_col,\n",
    "                \"threshold\": thr,\n",
    "                \"AUC\": auc,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": prec,\n",
    "                \"recall_sensibilidade\": sens,\n",
    "                \"especificidade\": espec,\n",
    "                \"f1\": f1,\n",
    "                \"youden\": youden,\n",
    "                \"n_treino\": len(X_train),\n",
    "                \"n_teste\": len(X_test),\n",
    "                \"n_pos_treino\": int(y_train.sum()),\n",
    "                \"n_pos_teste\": int(y_test.sum()),\n",
    "                \"limiar_casos_p\": percentile_limiar,\n",
    "                \"valor_limiar_casos\": limiar\n",
    "            })\n",
    "\n",
    "            # Atualizar melhor threshold (maior índice de Youden)\n",
    "            if youden > best_youden:\n",
    "                best_youden = youden\n",
    "                best_thr = thr\n",
    "                best_metrics = {\n",
    "                    \"accuracy\": acc,\n",
    "                    \"precision\": prec,\n",
    "                    \"recall_sensibilidade\": sens,\n",
    "                    \"especificidade\": espec,\n",
    "                    \"f1\": f1\n",
    "                }\n",
    "\n",
    "        if best_thr is None:\n",
    "            print(f\"[AVISO] Não foi possível definir best_threshold para {target_col}. Pulando resumo.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Melhor limiar para {target_col} (Youden): {best_thr:.2f}\")\n",
    "        print(f\"  Sensibilidade: {best_metrics['recall_sensibilidade']:.3f}  \"\n",
    "              f\"Especificidade: {best_metrics['especificidade']:.3f}  \"\n",
    "              f\"Acurácia: {best_metrics['accuracy']:.3f}\")\n",
    "\n",
    "        # Matriz de confusão no melhor threshold\n",
    "        y_pred_best = (y_proba >= best_thr).astype(int)\n",
    "        cm = confusion_matrix(y_test, y_pred_best, labels=[0, 1])\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=[\"Real 0 (não epidêmico)\", \"Real 1 (epidêmico)\"],\n",
    "            columns=[\"Previsto 0\", \"Previsto 1\"]\n",
    "        )\n",
    "\n",
    "        fig_cm, ax_cm = plt.subplots(figsize=(6, 5))\n",
    "        sns.heatmap(cm_df, annot=True, fmt=\"d\", ax=ax_cm)\n",
    "        ax_cm.set_title(f\"Matriz de Confusão — {target_col}\\nThreshold = {best_thr:.2f}\")\n",
    "        ax_cm.set_ylabel(\"Real\")\n",
    "        ax_cm.set_xlabel(\"Previsto\")\n",
    "        fig_cm.tight_layout()\n",
    "\n",
    "        cm_path = output_dir_class / f\"CM_{target_col}_best.png\"\n",
    "        fig_cm.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig_cm)\n",
    "\n",
    "        # Linha do resumo para essa doença\n",
    "        resumo_linhas.append({\n",
    "            \"doenca\": target_col,\n",
    "            \"AUC\": auc,\n",
    "            \"best_threshold\": best_thr,\n",
    "            \"accuracy_best\": best_metrics[\"accuracy\"],\n",
    "            \"precision_best\": best_metrics[\"precision\"],\n",
    "            \"recall_sensibilidade_best\": best_metrics[\"recall_sensibilidade\"],\n",
    "            \"especificidade_best\": best_metrics[\"especificidade\"],\n",
    "            \"f1_best\": best_metrics[\"f1\"],\n",
    "            \"n_treino\": len(X_train),\n",
    "            \"n_teste\": len(X_test),\n",
    "            \"n_pos_treino\": int(y_train.sum()),\n",
    "            \"n_pos_teste\": int(y_test.sum()),\n",
    "            \"limiar_casos_percentil\": percentile_limiar,\n",
    "            \"valor_limiar_casos\": limiar\n",
    "        })\n",
    "\n",
    "    # Construir DataFrames finais\n",
    "    resumo_df = pd.DataFrame(resumo_linhas)\n",
    "    thresholds_all_df = pd.DataFrame(thresholds_linhas)\n",
    "\n",
    "    return resumo_df, thresholds_all_df\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Rodar Modelo 4 em df\n",
    "# =======================\n",
    "\n",
    "resumo_epidemico, thresholds_epidemico = classificar_meses_epidemicos(df)\n",
    "\n",
    "print(\"\\n=== RESUMO GERAL CLASSIFICAÇÃO EPIDÊMICO vs NÃO ===\")\n",
    "print(resumo_epidemico)\n",
    "\n",
    "\n",
    "# ==============================================\n",
    "# Salvar tabelas em Excel (uma aba por doença + Resumo)\n",
    "# ==============================================\n",
    "\n",
    "tabela_dir = base_path / \"RF_Modelo4_Classificacao_Epidemico\"\n",
    "tabela_dir.mkdir(exist_ok=True)\n",
    "\n",
    "excel_path = tabela_dir / \"Tabela_Modelo4_Classificacao_Epidemico.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    # aba Resumo\n",
    "    resumo_epidemico.to_excel(writer, sheet_name=\"Resumo\", index=False)\n",
    "\n",
    "    # abas por doença com tabela de thresholds\n",
    "    for doenca in possible_disease_cols:\n",
    "        df_thr_doenca = thresholds_epidemico[thresholds_epidemico[\"doenca\"] == doenca].copy()\n",
    "        if df_thr_doenca.empty:\n",
    "            continue\n",
    "\n",
    "        sheet_name = doenca[:31]\n",
    "        df_thr_doenca.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"\\nArquivo Excel de classificação salvo em: {excel_path}\")\n",
    "print(f\"Figuras (ROC e Matriz de Confusão) salvas em: {output_dir_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
